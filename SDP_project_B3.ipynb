{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VaibhavLohitashv/Comparing-ML-models-for-Alzheimers-Detection/blob/main/SDP_project_B3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check Specification of runtime"
      ],
      "metadata": {
        "id": "Ds2l6zXI9Vd-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /proc/cpuinfo"
      ],
      "metadata": {
        "id": "dJx1tJmj_-7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!df -h"
      ],
      "metadata": {
        "id": "xY6q4yd79UlH",
        "outputId": "51584613-af5e-40fe-b5d2-adcd6d826dfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filesystem      Size  Used Avail Use% Mounted on\n",
            "overlay         108G   38G   71G  35% /\n",
            "tmpfs            64M     0   64M   0% /dev\n",
            "shm             5.8G     0  5.8G   0% /dev/shm\n",
            "/dev/root       2.0G  1.2G  775M  61% /usr/sbin/docker-init\n",
            "tmpfs           6.4G   72K  6.4G   1% /var/colab\n",
            "/dev/sda1        85G   66G   19G  78% /kaggle/input\n",
            "tmpfs           6.4G     0  6.4G   0% /proc/acpi\n",
            "tmpfs           6.4G     0  6.4G   0% /proc/scsi\n",
            "tmpfs           6.4G     0  6.4G   0% /sys/firmware\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing required Libraries like:\n",
        "-  pandas\n",
        "-  numpy\n",
        "-  matplotlib\n",
        "-  seaborn\n",
        "-  sklearn"
      ],
      "metadata": {
        "id": "Q1iKAgXJiGcI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Handling & Visualization Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb  # using alias for seaborn\n",
        "\n",
        "# Preprocessing\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "# Warnings Handling\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"seaborn\")\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"IPython.core.pylabtools\")\n",
        "\n",
        "# Resampling Technique\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Model Selection and Preprocessing Tools\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "\n",
        "# Linear and Probabilistic Models\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# from sklearn.linear_model import BayesianRidge\n",
        "\n",
        "# Tree-Based & Ensemble Models\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# from sklearn.ensemble import GradientBoostingClassifier\n",
        "# from sklearn.ensemble import AdaBoostClassifier\n",
        "# from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Neighbors\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "#  Neural Network Model\n",
        "# from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# External ML Library\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Evaluation Metrics\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score,\n",
        "    f1_score, classification_report, confusion_matrix\n",
        ")\n",
        "\n",
        "# Hyperparameter Search\n",
        "# from sklearn.model_selection import GridSearchCV\n",
        "# from sklearn.model_selection import RandomizedSearchCV\n",
        "# from sklearn.exceptions import FitFailedWarning\n",
        "\n",
        "\n",
        "print(\"all required libraries are imported successfully.\")\n"
      ],
      "metadata": {
        "id": "bq7uabKoXTDu",
        "outputId": "45adce20-3964-4a73-d5e2-44e9047167d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "all required libraries are imported successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting data set from already downloaded .csv file.\n",
        "### Source: https://www.kaggle.com/datasets/ankushpanday1/alzheimers-prediction-dataset-global"
      ],
      "metadata": {
        "id": "qnVhfTuyiTCX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_main = pd.read_csv('/content/alzheimers_prediction_dataset.csv')"
      ],
      "metadata": {
        "id": "0vnJv9RSa17b",
        "outputId": "ffa4cdb9-d85d-47f4-ee5b-544ef564531f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/alzheimers_prediction_dataset.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2-1785790670.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_main\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/alzheimers_prediction_dataset.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/alzheimers_prediction_dataset.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Information of Data"
      ],
      "metadata": {
        "id": "SauABe7yZbwm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_main.head()"
      ],
      "metadata": {
        "id": "BR1zm3lMcIEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_main.info()"
      ],
      "metadata": {
        "id": "d7obMCLBcLgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Log shape before any processing\n",
        "print(f\"Dataset Shape: {df_main.shape}\")\n",
        "\n",
        "# --- Check for Missing Values ---\n",
        "print(\"\\nPercentage of Missing Values per Column:\")\n",
        "missing_ratio = df_main.isnull().mean() * 100\n",
        "print(missing_ratio.round(2))\n",
        "\n",
        "# --- Check for Duplicates ---\n",
        "print(\"\\nPercentage of Duplicate Rows:\")\n",
        "duplicate_ratio = df_main.duplicated().mean() * 100\n",
        "print(f\"{duplicate_ratio:.2f}%\")\n",
        "\n",
        "# Optional Debug Logging\n",
        "if duplicate_ratio > 0:\n",
        "    print(\"Warning: Dataset contains duplicate entries.\")\n",
        "else:\n",
        "    print(\"No duplicate rows found.\")\n"
      ],
      "metadata": {
        "id": "4z89mHlKcren"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to identify outliers using IQR method\n",
        "def detect_outliers(df, feature_name):\n",
        "    q1 = df[feature_name].quantile(0.25)\n",
        "    q3 = df[feature_name].quantile(0.75)\n",
        "    iqr = q3 - q1\n",
        "    lower_bound = q1 - 1.5 * iqr\n",
        "    upper_bound = q3 + 1.5 * iqr\n",
        "    outlier_rows = df[(df[feature_name] < lower_bound) | (df[feature_name] > upper_bound)]\n",
        "    return outlier_rows\n",
        "\n",
        "# Initialize an empty DataFrame to store all outliers\n",
        "combined_outliers = pd.DataFrame()\n",
        "\n",
        "# Loop through all numeric columns to detect and collect outliers\n",
        "numeric_cols = df_main.select_dtypes(include=[\"number\"]).columns\n",
        "\n",
        "for feature in numeric_cols:\n",
        "    col_outliers = detect_outliers(df_main, feature)\n",
        "    if not col_outliers.empty:\n",
        "        combined_outliers = pd.concat([combined_outliers, col_outliers], axis=0)\n",
        "\n",
        "# Drop duplicate indices if any\n",
        "combined_outliers.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Summarize the outlier analysis\n",
        "num_outliers = combined_outliers.shape[0]\n",
        "dataset_size = df_main.shape[0]\n",
        "outlier_percent = (num_outliers / dataset_size) * 100\n",
        "\n",
        "# Reporting\n",
        "print(\"\\nOutlier Detection Summary:\")\n",
        "if num_outliers == 0:\n",
        "    print(\"No outliers detected in the dataset.\")\n",
        "else:\n",
        "    print(f\"Total Outliers Found: {num_outliers}\")\n",
        "    print(f\"Outlier Proportion: {outlier_percent:.2f}% of the dataset\")\n",
        "\n",
        "# Optional: view outliers\n",
        "# print(combined_outliers.head())\n"
      ],
      "metadata": {
        "id": "3f4QzGaZhRqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory data analysis: Data Distribution"
      ],
      "metadata": {
        "id": "BOPGrc8QVPGf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the overall plot size\n",
        "plt.figure(figsize=(18, 12))\n",
        "\n",
        "# --- Plot 1: Age Histogram ---\n",
        "plt.subplot(2, 3, 1)\n",
        "sb.histplot(data=df_main, x='Age', bins=30, kde=True, color='lightblue')\n",
        "plt.title('Distribution of Age')\n",
        "plt.xlabel('Age (years)')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "# --- Plot 2: BMI Histogram ---\n",
        "plt.subplot(2, 3, 2)\n",
        "sb.histplot(df_main['BMI'], color='coral', bins=30, kde=True)\n",
        "plt.title('Distribution of BMI')\n",
        "plt.xlabel('BMI Value')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "# --- Plot 3: Cognitive Score Histogram ---\n",
        "plt.subplot(2, 3, 3)\n",
        "sb.histplot(df_main['Cognitive Test Score'], bins=30, kde=True, color='mediumseagreen')\n",
        "plt.title('Cognitive Test Scores')\n",
        "plt.xlabel('Score')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "# --- Plot 4: Gender Count Plot ---\n",
        "plt.subplot(2, 3, 4)\n",
        "sb.countplot(x='Gender', data=df_main, palette='cool')\n",
        "plt.title('Gender Breakdown')\n",
        "plt.xlabel('Gender')\n",
        "plt.ylabel('Total Count')\n",
        "\n",
        "# --- Plot 5: Smoking Status Count Plot ---\n",
        "plt.subplot(2, 3, 5)\n",
        "sb.countplot(data=df_main, x='Smoking Status', palette='pastel')\n",
        "plt.title('Smoking Habits')\n",
        "plt.xlabel('Smoking Status')\n",
        "plt.ylabel('Total Count')\n",
        "\n",
        "# --- Plot 6: Alzheimer’s Diagnosis Count Plot ---\n",
        "plt.subplot(2, 3, 6)\n",
        "sb.countplot(x=\"Alzheimer’s Diagnosis\", data=df_main, palette='Set3')\n",
        "plt.title('Alzheimer’s Diagnosis Count')\n",
        "plt.xlabel('Diagnosis')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "# Adjust subplot spacing\n",
        "plt.tight_layout()\n",
        "\n",
        "# Optional print to confirm visualization step\n",
        "print(\"Visualizations rendered successfully.\")\n",
        "\n",
        "# Render the plots\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "-DIepyNLVN-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory data analysis : Correlation Analysis"
      ],
      "metadata": {
        "id": "OiFwmb_dgNDD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a dictionary to store encoders for each categorical column\n",
        "encoders_map = {}\n",
        "\n",
        "# Apply Label Encoding to all categorical columns\n",
        "categorical_features = df_main.select_dtypes(include=['object']).columns\n",
        "for feature in categorical_features:\n",
        "    encoder = LabelEncoder()\n",
        "    df_main[feature] = encoder.fit_transform(df_main[feature])\n",
        "    encoders_map[feature] = encoder  # Save encoder for possible inverse transform later\n",
        "\n",
        "# Capture encoded column names for reference\n",
        "encoded_columns = list(encoders_map.keys())\n",
        "\n",
        "# Identify numerical columns to scale (excluding those already encoded)\n",
        "all_numerics = df_main.select_dtypes(include=['int64', 'float64']).columns\n",
        "columns_for_scaling = [col for col in all_numerics if col not in encoded_columns]\n",
        "\n",
        "# Initialize and apply standard scaler\n",
        "scaling_tool = StandardScaler()\n",
        "df_main[columns_for_scaling] = scaling_tool.fit_transform(df_main[columns_for_scaling])\n",
        "\n",
        "# Log confirmation\n",
        "print(\"Encoding complete for categorical features.\")\n",
        "print(\"Scaling applied to numerical columns (excluding encoded categorical features).\")\n",
        "\n",
        "# Preview scaled data\n",
        "print(\"\\nSample of Scaled Numerical Features:\")\n",
        "print(df_main[columns_for_scaling].head())\n"
      ],
      "metadata": {
        "id": "PjoJCNDegKl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -- Encode Categorical Columns ---\n",
        "enc_map = {}\n",
        "categorical_vars = df_main.select_dtypes(include=['object']).columns\n",
        "\n",
        "for feature in categorical_vars:\n",
        "    le = LabelEncoder()\n",
        "    df_main[feature] = le.fit_transform(df_main[feature])\n",
        "    enc_map[feature] = le  # Saving encoder for reference\n",
        "\n",
        "print(\"Label encoding applied to all categorical variables.\")\n",
        "\n",
        "# --- Compute Correlation Matrix ---\n",
        "print(\"\\nGenerating correlation matrix using Pearson method...\")\n",
        "corr_mat = df_main.corr(method='pearson')\n",
        "\n",
        "# --- Plot the Correlation Heatmap ---\n",
        "plt.figure(figsize=(18, 10))\n",
        "sb.heatmap(corr_mat, annot=True, cmap=\"coolwarm\", cbar=True, fmt=\".2f\", linewidths=0.5, vmin=-1, vmax=1)\n",
        "plt.title(\"Feature Correlation Heatmap\", fontsize=16, fontweight='bold')\n",
        "plt.xticks(rotation=45)\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "t8C_3xWKgZu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "2# Select relevant features for correlation analysis\n",
        "features_to_plot = ['Age', 'Family History of Alzheimer’s',\n",
        "                    'Genetic Risk Factor (APOE-ε4 allele)',\n",
        "                    'Alzheimer’s Diagnosis']\n",
        "\n",
        "# Compute correlation matrix for selected features\n",
        "focused_corr = df_main[features_to_plot].corr(method='pearson')\n",
        "\n",
        "# Plotting the heatmap\n",
        "plt.figure(figsize=(12, 6))\n",
        "sb.heatmap(focused_corr, annot=True, cmap='coolwarm', fmt=\".2f\", linecolor='white', linewidths=0.3, vmin=-1, vmax=1)\n",
        "plt.title(\"Correlation Between Age, Genetic Factors & Diagnosis\", fontsize=14)\n",
        "plt.xticks(rotation=15)\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "OvmKe95DglyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparison of Machine Learning Model Performance"
      ],
      "metadata": {
        "id": "Xjj0m6JuqUfN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select input features and target variable\n",
        "features = df_main[['Age', 'Family History of Alzheimer’s', 'Genetic Risk Factor (APOE-ε4 allele)']]\n",
        "target = df_main['Alzheimer’s Diagnosis']\n",
        "\n",
        "# Split dataset into training and testing sets (80-20 ratio)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    features, target, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Dictionary of models to compare\n",
        "ml_models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=10000, random_state=42),\n",
        "    \"K-Nearest Neighbors\": KNeighborsClassifier(n_neighbors=3),\n",
        "    \"Decision Tree Classifier\": DecisionTreeClassifier(random_state=42),\n",
        "    \"Random Forest Classifier\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    \"XGBoost Classifier\": XGBClassifier(n_estimators=100, use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "}\n",
        "\n",
        "# Define evaluation function for model performance\n",
        "def assess_model_performance(estimator, X_tr, X_te, y_tr, y_te):\n",
        "    estimator.fit(X_tr, y_tr)\n",
        "    predictions = estimator.predict(X_te)\n",
        "\n",
        "    acc = accuracy_score(y_te, predictions)\n",
        "    prec = precision_score(y_te, predictions, average='weighted', zero_division=0)\n",
        "    rec = recall_score(y_te, predictions, average='weighted', zero_division=0)\n",
        "    f1 = f1_score(y_te, predictions, average='weighted', zero_division=0)\n",
        "\n",
        "    # Optional: print to debug individual scores\n",
        "    print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "    return acc, prec, rec, f1\n"
      ],
      "metadata": {
        "id": "B7_pY5lMqU_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List to store evaluation outcomes\n",
        "model_performance_log = []\n",
        "\n",
        "# Evaluate each model and collect metrics\n",
        "for model_name, clf in ml_models.items():\n",
        "    acc, prec, rec, f1_score_val = assess_model_performance(clf, X_train, X_test, y_train, y_test)\n",
        "\n",
        "    model_performance_log.append({\n",
        "        \"Model Name\": model_name,\n",
        "        \"Accuracy (%)\": round(acc * 100, 2),\n",
        "        \"Precision (%)\": round(prec * 100, 2),\n",
        "        \"Recall (%)\": round(rec * 100, 2),\n",
        "        \"F1 Score (%)\": round(f1_score_val * 100, 2)\n",
        "    })\n",
        "\n",
        "# Convert results into a readable DataFrame\n",
        "performance_df = pd.DataFrame(model_performance_log)\n",
        "\n",
        "# Display the performance table\n",
        "performance_df\n"
      ],
      "metadata": {
        "id": "Trr5WIlQqv0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Conclusion"
      ],
      "metadata": {
        "id": "sTefVBfFr2X5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify the best-performing model based on highest accuracy\n",
        "top_model_row = performance_df.loc[performance_df['Accuracy (%)'].idxmax()]\n",
        "print(\"\\nBest Performing Model (Based on Accuracy):\")\n",
        "print(top_model_row)\n",
        "\n",
        "# Define evaluation metrics and visualization parameters\n",
        "score_labels = [\"Accuracy (%)\", \"Precision (%)\", \"Recall (%)\", \"F1 Score (%)\"]\n",
        "bar_colors = [\"#3498db\", \"#f39c12\", \"#2ecc71\", \"#e74c3c\"]\n",
        "\n",
        "# Initialize horizontal bar chart\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "# Create grouped horizontal bars for each metric across all models\n",
        "for idx, metric in enumerate(score_labels):\n",
        "    ax.barh(\n",
        "        performance_df[\"Model Name\"] + f\" [{metric}]\",\n",
        "        performance_df[metric],\n",
        "        color=bar_colors[idx],\n",
        "        alpha=0.75,\n",
        "        height=0.55,\n",
        "        label=metric\n",
        "    )\n",
        "\n",
        "# Customize the plot\n",
        "ax.set_xlabel(\"Metric Score (%)\", fontsize=12)\n",
        "ax.set_title(\"Comparative Analysis of Machine Learning Models\", fontsize=16)\n",
        "ax.legend(title=\"Evaluation Metrics\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.grid(True, axis='x', linestyle='--', alpha=0.5)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Summary of best model\n",
        "print(f\"\\nOptimal Model Selected: {top_model_row['Model Name']}  ---> Accuracy: {top_model_row['Accuracy (%)']}%\")\n"
      ],
      "metadata": {
        "id": "ipZy_iHdr6_x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}